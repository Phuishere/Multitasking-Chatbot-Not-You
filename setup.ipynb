{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m venv venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting duckduckgo-search==8.0.2 (from -r requirements.txt (line 1))\n",
      "  Using cached duckduckgo_search-8.0.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting huggingface-hub==0.30.2 (from huggingface-hub[hf_xet]==0.30.2->-r requirements.txt (line 2))\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting llama-cpp-python==0.3.8 (from -r requirements.txt (line 3))\n",
      "  Using cached llama_cpp_python-0.3.8.tar.gz (67.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting llama-cpp-agent==0.2.35 (from -r requirements.txt (line 4))\n",
      "  Using cached llama_cpp_agent-0.2.35-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index==0.12.34 (from -r requirements.txt (line 5))\n",
      "  Using cached llama_index-0.12.34-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting regex==2024.11.6 (from -r requirements.txt (line 6))\n",
      "  Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting streamlit==1.45.0 (from -r requirements.txt (line 7))\n",
      "  Using cached streamlit-1.45.0-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting wikitextparser==0.56.4 (from -r requirements.txt (line 8))\n",
      "  Using cached wikitextparser-0.56.4-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting click>=8.1.8 (from duckduckgo-search==8.0.2->-r requirements.txt (line 1))\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting primp>=0.15.0 (from duckduckgo-search==8.0.2->-r requirements.txt (line 1))\n",
      "  Using cached primp-0.15.0-cp38-abi3-win_amd64.whl.metadata (13 kB)\n",
      "Collecting lxml>=5.3.0 (from duckduckgo-search==8.0.2->-r requirements.txt (line 1))\n",
      "  Downloading lxml-6.0.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting filelock (from huggingface-hub==0.30.2->huggingface-hub[hf_xet]==0.30.2->-r requirements.txt (line 2))\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub==0.30.2->huggingface-hub[hf_xet]==0.30.2->-r requirements.txt (line 2))\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in .\\venv\\lib\\site-packages (from huggingface-hub==0.30.2->huggingface-hub[hf_xet]==0.30.2->-r requirements.txt (line 2)) (25.0)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub==0.30.2->huggingface-hub[hf_xet]==0.30.2->-r requirements.txt (line 2))\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting requests (from huggingface-hub==0.30.2->huggingface-hub[hf_xet]==0.30.2->-r requirements.txt (line 2))\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub==0.30.2->huggingface-hub[hf_xet]==0.30.2->-r requirements.txt (line 2))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in .\\venv\\lib\\site-packages (from huggingface-hub==0.30.2->huggingface-hub[hf_xet]==0.30.2->-r requirements.txt (line 2)) (4.14.0)\n",
      "Collecting numpy>=1.20.0 (from llama-cpp-python==0.3.8->-r requirements.txt (line 3))\n",
      "  Downloading numpy-2.3.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.9 kB ? eta -:--:--\n",
      "     ------------------- ------------------ 30.7/60.9 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.9/60.9 kB 803.9 kB/s eta 0:00:00\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.3.8->-r requirements.txt (line 3))\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting jinja2>=2.11.3 (from llama-cpp-python==0.3.8->-r requirements.txt (line 3))\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pydantic>=2.5.3 (from llama-cpp-agent==0.2.35->-r requirements.txt (line 4))\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "     ---------------------------------------- 0.0/68.0 kB ? eta -:--:--\n",
      "     ------------------------ --------------- 41.0/68.0 kB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 68.0/68.0 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting docstring-parser (from llama-cpp-agent==0.2.35->-r requirements.txt (line 4))\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting aiohttp (from llama-cpp-agent==0.2.35->-r requirements.txt (line 4))\n",
      "  Downloading aiohttp-3.12.13-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_index_agent_openai-0.4.11-py3-none-any.whl.metadata (439 bytes)\n",
      "Collecting llama-index-cli<0.5,>=0.4.1 (from llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_index_cli-0.4.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting llama-index-core<0.13,>=0.12.34 (from llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_index_core-0.12.44-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.7.7-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-llms-openai<0.4,>=0.3.0 (from llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_index_llms_openai-0.3.44-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5,>=0.4.0 (from llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_index_program_openai-0.3.2-py3-none-any.whl.metadata (473 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_index_question_gen_openai-0.3.1-py3-none-any.whl.metadata (492 bytes)\n",
      "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_index_readers_file-0.4.9-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Using cached altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting packaging>=20.9 (from huggingface-hub==0.30.2->huggingface-hub[hf_xet]==0.30.2->-r requirements.txt (line 2))\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pandas<3,>=1.4.0 (from streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Downloading pandas-2.3.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pillow<12,>=7.1.0 (from streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Using cached pillow-11.2.1-cp311-cp311-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting protobuf<7,>=3.20 (from streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Downloading pyarrow-20.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Using cached watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in .\\venv\\lib\\site-packages (from streamlit==1.45.0->-r requirements.txt (line 7)) (6.5.1)\n",
      "Requirement already satisfied: wcwidth in .\\venv\\lib\\site-packages (from wikitextparser==0.56.4->-r requirements.txt (line 8)) (0.2.13)\n",
      "Collecting hf-xet>=0.1.4 (from huggingface-hub[hf_xet]==0.30.2->-r requirements.txt (line 2))\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-win_amd64.whl.metadata (883 bytes)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Downloading jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Downloading narwhals-1.44.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in .\\venv\\lib\\site-packages (from click>=8.1.8->duckduckgo-search==8.0.2->-r requirements.txt (line 1)) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python==0.3.8->-r requirements.txt (line 3))\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "INFO: pip is looking at multiple versions of llama-index-agent-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_index_agent_openai-0.4.10-py3-none-any.whl.metadata (439 bytes)\n",
      "  Downloading llama_index_agent_openai-0.4.9-py3-none-any.whl.metadata (438 bytes)\n",
      "  Using cached llama_index_agent_openai-0.4.8-py3-none-any.whl.metadata (438 bytes)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.5,>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading openai-1.92.2-py3-none-any.whl.metadata (29 kB)\n",
      "INFO: pip is looking at multiple versions of llama-index-cli to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-index-cli<0.5,>=0.4.1 (from llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_index_cli-0.4.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting aiosqlite (from llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting banks<3,>=2.0.0 (from llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached banks-2.1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting httpx (from llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting llama-index-workflows<2,>=1.0.1 (from llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_index_workflows-1.0.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in .\\venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5)) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting setuptools>=80.9.0 (from llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sqlalchemy>=1.4.49 (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading sqlalchemy-2.0.41-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting tiktoken>=0.7.0 (from llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached wrapt-1.17.2-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->llama-cpp-agent==0.2.35->-r requirements.txt (line 4))\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->llama-cpp-agent==0.2.35->-r requirements.txt (line 4))\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->llama-cpp-agent==0.2.35->-r requirements.txt (line 4))\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->llama-cpp-agent==0.2.35->-r requirements.txt (line 4))\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->llama-cpp-agent==0.2.35->-r requirements.txt (line 4))\n",
      "  Downloading multidict-6.5.1-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->llama-cpp-agent==0.2.35->-r requirements.txt (line 4))\n",
      "  Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->llama-cpp-agent==0.2.35->-r requirements.txt (line 4))\n",
      "  Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl.metadata (76 kB)\n",
      "     ---------------------------------------- 0.0/76.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/76.3 kB ? eta -:--:--\n",
      "     ----- ---------------------------------- 10.2/76.3 kB ? eta -:--:--\n",
      "     ----- ---------------------------------- 10.2/76.3 kB ? eta -:--:--\n",
      "     --------------- ---------------------- 30.7/76.3 kB 262.6 kB/s eta 0:00:01\n",
      "     -------------------- ----------------- 41.0/76.3 kB 217.9 kB/s eta 0:00:01\n",
      "     ------------------------------ ------- 61.4/76.3 kB 273.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 76.3/76.3 kB 282.4 kB/s eta 0:00:00\n",
      "Collecting llama-cloud==0.1.26 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_cloud-0.1.26-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting certifi>=2024.7.4 (from llama-cloud==0.1.26->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "INFO: pip is looking at multiple versions of llama-index-program-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "INFO: pip is looking at multiple versions of llama-index-question-gen-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting beautifulsoup4<5,>=4.12.3 (from llama-index-readers-file<0.5,>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pandas<3,>=1.4.0 (from streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pypdf<6,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading pypdf-5.6.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5,>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_parse-0.6.37-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting joblib (from nltk>3.8.1->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit==1.45.0->-r requirements.txt (line 7)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<3,>=1.4.0->streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3,>=1.4.0->streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.5.3->llama-cpp-agent==0.2.35->-r requirements.txt (line 4))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.5.3->llama-cpp-agent==0.2.35->-r requirements.txt (line 4))\n",
      "  Using cached pydantic_core-2.33.2-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.5.3->llama-cpp-agent==0.2.35->-r requirements.txt (line 4))\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->huggingface-hub==0.30.2->huggingface-hub[hf_xet]==0.30.2->-r requirements.txt (line 2))\n",
      "  Using cached charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->huggingface-hub==0.30.2->huggingface-hub[hf_xet]==0.30.2->-r requirements.txt (line 2))\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub==0.30.2->huggingface-hub[hf_xet]==0.30.2->-r requirements.txt (line 2))\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting griffe (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: platformdirs in .\\venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5)) (4.3.8)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting anyio (from httpx->llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx->llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.45.0->-r requirements.txt (line 7))\n",
      "  Downloading rpds_py-0.25.1-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_index_instrumentation-0.2.0-py3-none-any.whl.metadata (252 bytes)\n",
      "Collecting llama-cloud-services>=0.6.37 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_cloud_services-0.6.37-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached jiter-0.10.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: six>=1.5 in .\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit==1.45.0->-r requirements.txt (line 7)) (1.17.0)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading greenlet-3.2.3-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13,>=0.12.34->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_parse-0.6.36-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting llama-cloud-services>=0.6.36 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_cloud_services-0.6.36-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_parse-0.6.35-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting llama-cloud-services>=0.6.35 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_cloud_services-0.6.35-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_parse-0.6.34-py3-none-any.whl.metadata (6.9 kB)\n",
      "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-cloud-services>=0.6.32 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading llama_cloud_services-0.6.34-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.32->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index==0.12.34->-r requirements.txt (line 5))\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Using cached duckduckgo_search-8.0.2-py3-none-any.whl (18 kB)\n",
      "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Using cached llama_cpp_agent-0.2.35-py3-none-any.whl (89 kB)\n",
      "Using cached llama_index-0.12.34-py3-none-any.whl (7.0 kB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Using cached streamlit-1.45.0-py3-none-any.whl (9.9 MB)\n",
      "Using cached wikitextparser-0.56.4-py3-none-any.whl (66 kB)\n",
      "Using cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "   ---------------------------------------- 0.0/102.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/102.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/102.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/102.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/102.2 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/102.2 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/102.2 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/102.2 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/102.2 kB ? eta -:--:--\n",
      "   ----------- --------------------------- 30.7/102.2 kB 131.3 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 30.7/102.2 kB 131.3 kB/s eta 0:00:01\n",
      "   --------------- ----------------------- 41.0/102.2 kB 109.3 kB/s eta 0:00:01\n",
      "   --------------- ----------------------- 41.0/102.2 kB 109.3 kB/s eta 0:00:01\n",
      "   ----------------------- --------------- 61.4/102.2 kB 136.5 kB/s eta 0:00:01\n",
      "   ----------------------- --------------- 61.4/102.2 kB 136.5 kB/s eta 0:00:01\n",
      "   ------------------------------- ------- 81.9/102.2 kB 158.2 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 92.2/102.2 kB 158.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- 102.2/102.2 kB 168.1 kB/s eta 0:00:00\n",
      "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Downloading hf_xet-1.1.5-cp37-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.7 MB 495.5 kB/s eta 0:00:06\n",
      "    --------------------------------------- 0.1/2.7 MB 409.6 kB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.1/2.7 MB 438.9 kB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.1/2.7 MB 422.8 kB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.1/2.7 MB 437.6 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.1/2.7 MB 448.2 kB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.2/2.7 MB 477.7 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.2/2.7 MB 525.1 kB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.2/2.7 MB 538.9 kB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.3/2.7 MB 592.4 kB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 0.3/2.7 MB 636.4 kB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.4/2.7 MB 692.4 kB/s eta 0:00:04\n",
      "   ------ --------------------------------- 0.5/2.7 MB 739.8 kB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.5/2.7 MB 780.5 kB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.6/2.7 MB 849.6 kB/s eta 0:00:03\n",
      "   --------- ------------------------------ 0.7/2.7 MB 906.8 kB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.9/2.7 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.1/2.7 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.2/2.7 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.4/2.7 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.7/2.7 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.9/2.7 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.1/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.4/2.7 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.7/2.7 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 2.2 MB/s eta 0:00:00\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached llama_index_agent_openai-0.4.8-py3-none-any.whl (14 kB)\n",
      "Using cached llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_core-0.12.44-py3-none-any.whl (7.6 MB)\n",
      "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/7.6 MB 7.0 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.5/7.6 MB 6.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.8/7.6 MB 6.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.1/7.6 MB 6.7 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.4/7.6 MB 6.7 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.6/7.6 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.0/7.6 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.4/7.6 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.7/7.6 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.4/7.6 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.8/7.6 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.3/7.6 MB 7.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.7/7.6 MB 7.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.1/7.6 MB 8.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 5.6/7.6 MB 8.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.0/7.6 MB 8.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.5/7.6 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.0/7.6 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.5/7.6 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.6/7.6 MB 8.6 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.12.13-cp311-cp311-win_amd64.whl (451 kB)\n",
      "   ---------------------------------------- 0.0/451.4 kB ? eta -:--:--\n",
      "   --------------------------------------  450.6/451.4 kB 14.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 451.4/451.4 kB 9.4 MB/s eta 0:00:00\n",
      "Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.7.7-py3-none-any.whl (16 kB)\n",
      "Downloading llama_cloud-0.1.26-py3-none-any.whl (266 kB)\n",
      "   ---------------------------------------- 0.0/266.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 266.8/266.8 kB 8.3 MB/s eta 0:00:00\n",
      "Downloading llama_index_llms_openai-0.3.44-py3-none-any.whl (24 kB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
      "Using cached llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.4.9-py3-none-any.whl (40 kB)\n",
      "   ---------------------------------------- 0.0/41.0 kB ? eta -:--:--\n",
      "   ---------------------------------------  41.0/41.0 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.0/41.0 kB 654.0 kB/s eta 0:00:00\n",
      "Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading lxml-6.0.0-cp311-cp311-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.6/4.0 MB 12.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.1/4.0 MB 13.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.6/4.0 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.3/4.0 MB 13.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.9/4.0 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.6/4.0 MB 13.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.0/4.0 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 12.1 MB/s eta 0:00:00\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading numpy-2.3.1-cp311-cp311-win_amd64.whl (13.0 MB)\n",
      "   ---------------------------------------- 0.0/13.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.6/13.0 MB 13.5 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.4/13.0 MB 15.0 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 2.0/13.0 MB 16.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.7/13.0 MB 15.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.4/13.0 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.1/13.0 MB 15.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.8/13.0 MB 16.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.4/13.0 MB 16.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.4/13.0 MB 16.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.1/13.0 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 8.1/13.0 MB 17.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.8/13.0 MB 17.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.8/13.0 MB 18.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.7/13.0 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.0/13.0 MB 18.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.6/13.0 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.0/13.0 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.0/13.0 MB 19.3 MB/s eta 0:00:00\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.5/11.6 MB 24.6 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.9/11.6 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.9/11.6 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.2/11.6 MB 28.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.1/11.6 MB 26.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.6/11.6 MB 26.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.9/11.6 MB 28.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.4/11.6 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.6 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 27.3 MB/s eta 0:00:00\n",
      "Using cached pillow-11.2.1-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "Using cached primp-0.15.0-cp38-abi3-win_amd64.whl (3.1 MB)\n",
      "Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "   ---------------------------------------- 0.0/435.3 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 317.4/435.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 435.3/435.3 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading pyarrow-20.0.0-cp311-cp311-win_amd64.whl (25.8 MB)\n",
      "   ---------------------------------------- 0.0/25.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.6/25.8 MB 33.9 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 2.7/25.8 MB 33.6 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 2.9/25.8 MB 26.3 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 4.2/25.8 MB 24.6 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 6.9/25.8 MB 31.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 8.6/25.8 MB 34.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 8.9/25.8 MB 33.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 9.8/25.8 MB 29.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 13.1/25.8 MB 36.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 13.3/25.8 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.9/25.8 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.9/25.8 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.5/25.8 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.4/25.8 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.7/25.8 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.8/25.8 MB 32.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.8 MB 38.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.8/25.8 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.8/25.8 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.8/25.8 MB 29.7 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "   ---------------------------------------- 0.0/444.8 kB ? eta -:--:--\n",
      "   ---------------------------------------  440.3/444.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 444.8/444.8 kB 9.2 MB/s eta 0:00:00\n",
      "Using cached pydantic_core-2.33.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "   ---------------------------------------- 0.0/162.0 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 61.4/162.0 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 162.0/162.0 kB 1.9 MB/s eta 0:00:00\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached banks-2.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "   ---------------------------------------- 0.0/157.7 kB ? eta -:--:--\n",
      "   -------------------------------------- - 153.6/157.7 kB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 157.7/157.7 kB 3.1 MB/s eta 0:00:00\n",
      "Using cached charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl (105 kB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.0 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 41.0/44.0 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.0/44.0 kB 718.7 kB/s eta 0:00:00\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "   ---------------------------------------- 0.0/88.7 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 81.9/88.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 88.7/88.7 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading llama_index_workflows-1.0.1-py3-none-any.whl (36 kB)\n",
      "Downloading llama_parse-0.6.34-py3-none-any.whl (4.9 kB)\n",
      "Downloading llama_cloud_services-0.6.34-py3-none-any.whl (39 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Downloading multidict-6.5.1-cp311-cp311-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.7 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 41.0/44.7 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.7/44.7 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading narwhals-1.44.0-py3-none-any.whl (365 kB)\n",
      "   ---------------------------------------- 0.0/365.2 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 81.9/365.2 kB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 225.3/365.2 kB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  358.4/365.2 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 365.2/365.2 kB 2.5 MB/s eta 0:00:00\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Downloading openai-1.92.2-py3-none-any.whl (753 kB)\n",
      "   ---------------------------------------- 0.0/753.3 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 112.6/753.3 kB 3.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 276.5/753.3 kB 4.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 409.6/753.3 kB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 553.0/753.3 kB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 727.0/753.3 kB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 753.3/753.3 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.5/41.5 kB 665.1 kB/s eta 0:00:00\n",
      "Downloading pypdf-5.6.1-py3-none-any.whl (304 kB)\n",
      "   ---------------------------------------- 0.0/304.6 kB ? eta -:--:--\n",
      "   --------------------- ------------------ 163.8/304.6 kB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 304.6/304.6 kB 4.7 MB/s eta 0:00:00\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading sqlalchemy-2.0.41-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/2.1 MB 5.0 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/2.1 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.1 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.1 MB 5.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.4/2.1 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.7/2.1 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.0/2.1 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 5.4 MB/s eta 0:00:00\n",
      "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl (893 kB)\n",
      "   ---------------------------------------- 0.0/893.9 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 399.4/893.9 kB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 778.2/893.9 kB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 893.9/893.9 kB 7.1 MB/s eta 0:00:00\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "   ---------------------------------------- 0.0/129.8 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 122.9/129.8 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 129.8/129.8 kB 2.5 MB/s eta 0:00:00\n",
      "Using cached wrapt-1.17.2-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.7 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 81.9/86.7 kB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 86.7/86.7 kB 2.5 MB/s eta 0:00:00\n",
      "Using cached aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading greenlet-3.2.3-cp311-cp311-win_amd64.whl (297 kB)\n",
      "   ---------------------------------------- 0.0/297.0 kB ? eta -:--:--\n",
      "   ---------------------------------------  297.0/297.0 kB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 297.0/297.0 kB 6.2 MB/s eta 0:00:00\n",
      "Using cached jiter-0.10.0-cp311-cp311-win_amd64.whl (209 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading llama_index_instrumentation-0.2.0-py3-none-any.whl (14 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.25.1-cp311-cp311-win_amd64.whl (231 kB)\n",
      "   ---------------------------------------- 0.0/231.6 kB ? eta -:--:--\n",
      "   ------------------------------------- - 225.3/231.6 kB 14.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 231.6/231.6 kB 4.7 MB/s eta 0:00:00\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Using cached griffe-1.7.3-py3-none-any.whl (129 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): started\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): still running...\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): still running...\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.8-cp311-cp311-win_amd64.whl size=4882424 sha256=8b0d8f2ba62e91fc3018be67ba8af42baf512a31899347927b2a60154b28ae67\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\c0\\03\\66\\eb3810eafd55d921b2be32896d1f44313996982360663aa80b\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: striprtf, pytz, filetype, dirtyjson, wrapt, watchdog, urllib3, tzdata, typing-inspection, tqdm, toml, tenacity, soupsieve, sniffio, smmap, setuptools, rpds-py, regex, pyyaml, python-dotenv, pypdf, pydantic-core, pyarrow, protobuf, propcache, primp, pillow, packaging, numpy, networkx, narwhals, mypy-extensions, multidict, MarkupSafe, lxml, joblib, jiter, idna, hf-xet, h11, griffe, greenlet, fsspec, frozenlist, filelock, docstring-parser, distro, diskcache, click, charset_normalizer, certifi, cachetools, blinker, attrs, annotated-types, aiosqlite, aiohappyeyeballs, yarl, wikitextparser, typing-inspect, sqlalchemy, requests, referencing, pydantic, pandas, nltk, marshmallow, jinja2, httpcore, gitdb, duckduckgo-search, deprecated, beautifulsoup4, anyio, aiosignal, tiktoken, pydeck, llama-index-instrumentation, llama-cpp-python, jsonschema-specifications, huggingface-hub, httpx, gitpython, dataclasses-json, banks, aiohttp, openai, llama-index-workflows, llama-cpp-agent, llama-cloud, jsonschema, llama-index-core, altair, streamlit, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.5.0\n",
      "    Uninstalling setuptools-65.5.0:\n",
      "      Successfully uninstalled setuptools-65.5.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed MarkupSafe-3.0.2 aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.3.2 aiosqlite-0.21.0 altair-5.5.0 annotated-types-0.7.0 anyio-4.9.0 attrs-25.3.0 banks-2.1.2 beautifulsoup4-4.13.4 blinker-1.9.0 cachetools-5.5.2 certifi-2025.6.15 charset_normalizer-3.4.2 click-8.2.1 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 diskcache-5.6.3 distro-1.9.0 docstring-parser-0.16 duckduckgo-search-8.0.2 filelock-3.18.0 filetype-1.2.0 frozenlist-1.7.0 fsspec-2025.5.1 gitdb-4.0.12 gitpython-3.1.44 greenlet-3.2.3 griffe-1.7.3 h11-0.16.0 hf-xet-1.1.5 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.30.2 idna-3.10 jinja2-3.1.6 jiter-0.10.0 joblib-1.5.1 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 llama-cloud-0.1.26 llama-cloud-services-0.6.34 llama-cpp-agent-0.2.35 llama-cpp-python-0.3.8 llama-index-0.12.34 llama-index-agent-openai-0.4.8 llama-index-cli-0.4.1 llama-index-core-0.12.44 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.7.7 llama-index-instrumentation-0.2.0 llama-index-llms-openai-0.3.44 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.9 llama-index-readers-llama-parse-0.4.0 llama-index-workflows-1.0.1 llama-parse-0.6.34 lxml-6.0.0 marshmallow-3.26.1 multidict-6.5.1 mypy-extensions-1.1.0 narwhals-1.44.0 networkx-3.5 nltk-3.9.1 numpy-2.3.1 openai-1.92.2 packaging-24.2 pandas-2.2.3 pillow-11.2.1 primp-0.15.0 propcache-0.3.2 protobuf-6.31.1 pyarrow-20.0.0 pydantic-2.11.7 pydantic-core-2.33.2 pydeck-0.9.1 pypdf-5.6.1 python-dotenv-1.1.1 pytz-2025.2 pyyaml-6.0.2 referencing-0.36.2 regex-2024.11.6 requests-2.32.4 rpds-py-0.25.1 setuptools-80.9.0 smmap-5.0.2 sniffio-1.3.1 soupsieve-2.7 sqlalchemy-2.0.41 streamlit-1.45.0 striprtf-0.0.26 tenacity-9.1.2 tiktoken-0.9.0 toml-0.10.2 tqdm-4.67.1 typing-inspect-0.9.0 typing-inspection-0.4.1 tzdata-2025.2 urllib3-2.5.0 watchdog-6.0.0 wikitextparser-0.56.4 wrapt-1.17.2 yarl-1.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
