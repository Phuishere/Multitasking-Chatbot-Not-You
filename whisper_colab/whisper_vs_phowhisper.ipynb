{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triển khai trên Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Welcome to the advanced realm of long short-term memory networks, a breakthrough in the field of neural networks and machine learning. LSTMs are a special kind of recurrent neural network, capable of learning long-term dependencies in data sequences. LSTM networks consist of cells with gates that regulate the flow of information, including forget gates, input gates, and output gates. LSTMs are designed to remember patterns over time, making them ideal for time series analysis, language modeling, and more. Unlike traditional RNNs, LSTMs can remember information for long periods, overcoming issues like vanishing gradients. LSTMs power many modern AI applications, from speech recognition and language translation to predictive text input. LSTMs are a great way to understand the power of the machine. Despite their power, LSTMs come with challenges such as high computational costs and complex training processes. Long short-term memory networks have revolutionized how machines understand sequential data, paving the way for future AI innovations. Subscribe for more magical AI adventures. Александ ominтерs LSTMs LSTMs are an entries written by the way to scary. Eventually, they will be using CC to paddling the way to prepare Blood extraordinarily good and towards 것을 самом腹为. While multiple times, they will cover life in them with an option for machines, that were definitely interested in actic gl SIM material. Over the 80- cultura master machine, the cracks ofomes, which are somewhat important. Thanks to all of these new adventures will be covered today. Mix harmful for large Kantone syntax.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "path = \".//LSTM - Data Wil.mp3\"\n",
    "path_30 = \".//Secret Learn Math.mp3\"\n",
    "\n",
    "model = whisper.load_model(\"large-v3-turbo\")\n",
    "result = model.transcribe(path)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en\n",
      "The real secret is to be consistent. Every single day, you need to grind. You need to do mathematics. If you do math every day, you are going to get better at it. It doesn't matter if it's math. If you do anything every single day, you're going to get better at it. If you go ride your bike around the block every day, you're going to get better at riding your bike. If you play basketball every day, you're going to get better at playing basketball. So if you do math every day, you're going to get better at doing mathematics.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "path_30 = \".//Secret Learn Math.mp3\"\n",
    "model = whisper.load_model(\"large-v3-turbo\")\n",
    "\n",
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(path_30)\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "# decode the audio\n",
    "options = whisper.DecodingOptions()\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "# print the recognized text\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = result[\"text\"]\n",
    "\n",
    "prompt = \"Process this raw recorded text into meaningful and full script. The rules are: make few change to the original and write no notes and no phrases like 'Here is the script', 'I change this'. The script: \" + raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the advanced realm of long short-term memory networks, a breakthrough in the field of neural networks and machine learning. LSTMs are a special kind of recurrent neural network, capable of learning long-term dependencies in data sequences. LSTM networks consist of cells with gates that regulate the flow of information, including forget gates, input gates, and output gates. LSTMs are designed to remember patterns over time, making them ideal for time series analysis, language modeling, and more. Unlike traditional RNNs, LSTMs can remember information for long periods, overcoming issues like vanishing gradients. LSTMs power many modern AI applications, from speech recognition and language translation to predictive text input. LSTMs are a great way to understand the power of the machine. Despite their power, LSTMs come with challenges such as high computational costs and complex training processes. Long short-term memory networks have revolutionized how machines understand sequential data, paving the way for future AI innovations. Subscribe for more magical AI adventures. Vgomento PC\n"
     ]
    }
   ],
   "source": [
    "# Olama processing\n",
    "model_name = \"llama3.2:3b\"\n",
    "output_path = \".//answer.txt\"\n",
    "line_break = '''\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "response: ollama.ChatResponse = ollama.chat(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': prompt,\n",
    "        },\n",
    "])\n",
    "\n",
    "return_mes = response['message']['content']\n",
    "print(return_mes)\n",
    "\n",
    "with open(output_path, \"a\") as fa:\n",
    "    fa.write(line_break)\n",
    "    fa.write(return_mes)\n",
    "    \n",
    "\n",
    "# or access fields directly from the response object: print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiny.en',\n",
       " 'tiny',\n",
       " 'base.en',\n",
       " 'base',\n",
       " 'small.en',\n",
       " 'small',\n",
       " 'medium.en',\n",
       " 'medium',\n",
       " 'large-v1',\n",
       " 'large-v2',\n",
       " 'large-v3',\n",
       " 'large',\n",
       " 'large-v3-turbo',\n",
       " 'turbo']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper.available_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
